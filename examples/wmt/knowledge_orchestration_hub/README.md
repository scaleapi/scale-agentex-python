# Knowledge Orchestration Hub

A multi-agent system that orchestrates knowledge management across Confluence and deep research capabilities. Two specialized agents work together through a shared knowledge repository to provide comprehensive research and knowledge management.

## 🏗️ Architecture Overview

```mermaid
graph TD
    A[User Request] --> B[Conversational Agent<br/>Port 8000<br/><i>Sync AgentEx Agent</i>]
    B --> C{Request Type?}

    C -->|Deep Research<br/><i>ACP Protocol</i>| D[Deep Research Agent<br/>Port 8001<br/><i>Temporal AgentEx Agent</i>]
    C -->|Search/Chat| E[Shared Knowledge Repository<br/>Abstracted Backend]

    D --> F[Research Report]
    F --> G[Save to Knowledge Repository]
    G --> E

    B --> H[Confluence MCP Remote Server<br/>OAuth2.1]
    B --> I[OpenAI Web Search MCP Server]

    H --> J[Confluence Knowledge]
    I --> K[Web Search Results]

    E --> L[RAG Search Results]
    L --> B
    J --> B
    K --> B
    B --> M[Response to User]

    subgraph "Shared Knowledge Repository"
        E
        N[Research Reports]
        O[Document Metadata]
        E --- N
        E --- O
    end

    subgraph "MCP Servers"
        H
        I
    end

    classDef syncAgent fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef temporalAgent fill:#f3e5f5,stroke:#4a148c,stroke-width:2px;

    class B syncAgent;
    class D temporalAgent;
```

## 📁 Project Structure

```
knowledge_orchestration_hub/
├── wmt_conversationalist/      # Main chat interface with RAG
│   ├── manifest.yaml           # Agent configuration
│   ├── project/               # Agent implementation
│   └── ...                    # Generated by agentex init
├── wmt_deep_researcher/       # Deep research report generation
│   ├── manifest.yaml          # Agent configuration
│   ├── project/              # Agent implementation
│   └── ...                   # Generated by agentex init
├── shared_knowledge/         # Shared knowledge repository
│   ├── __init__.py
│   ├── repository.py         # Abstract repository interface
│   ├── backends/            # Pluggable storage backends
│   │   ├── __init__.py
│   │   ├── postgres.py      # PostgreSQL implementation
│   │   ├── sqlite.py        # SQLite implementation
│   │   └── memory.py        # In-memory implementation
│   ├── models.py            # Shared data models
│   └── rag_engine.py        # RAG search and retrieval
└── README.md                # This file
```

## 🤖 Agent Responsibilities

### **Conversational Agent**

- **Primary user interface** for the knowledge system
- **RAG-powered chat** using shared knowledge repository
- **Request routing** to appropriate specialized agents
- **Real-time search** across research reports and knowledge content
- **Direct access to Confluence** via MCP Remote Server (requires user delegated OAuth2.1)
- **Web search capabilities** via OpenAI's Hosted Web Search MCP Server

### **Deep Research Agent**

- **In-depth research reports** using web search and MCP tools
- **Based on 020_state_machine pattern** with enhanced persistence
- **Saves research outputs** to shared knowledge repository
- **Iterative research refinement** with user feedback

## 🗄️ Shared Knowledge Repository

The shared knowledge repository provides an abstracted interface for storing and retrieving knowledge, allowing easy swapping of storage backends:

### Supported Backends:

- **PostgreSQL** with pgvector for production use
- **SQLite** with vector extensions for development
- **In-Memory** for testing and demos

### Key Features:

- **Vector embeddings** for semantic search
- **Metadata tracking** and versioning
- **Source attribution** and citations
- **RAG engine** for context retrieval

## 🚀 Quick Start

### Prerequisites

- Python 3.10+
- Agentex SDK installed (`pip install agentex-sdk`)
- OpenAI API key
- Optional: Confluence API token for MCP Remote Server access

### Setup

1. **Start each agent**:

   ```bash
   cd wmt_conversationalist && agentex agents run --manifest manifest.yaml
   cd wmt_deep_researcher && agentex agents run --manifest manifest.yaml
   ```

2. **Configure knowledge repository backend**:

   ```bash
   export KNOWLEDGE_BACKEND=postgres  # or sqlite, memory
   export DATABASE_URL=postgresql://user:pass@localhost:5432/knowledge_hub
   ```

3. **Test the system**:
   - Open Agentex Web UI at `http://localhost:3001`
   - Select the conversational agent
   - Send test messages

## 📋 Example Workflows

### 1. Deep Research Request

Send to conversational agent:

```json
{
  "type": "research",
  "query": "Latest developments in AI agent orchestration",
  "depth": "comprehensive",
  "save_to_knowledge": true
}
```

### 2. Knowledge Search & Chat

Send to conversational agent:

```json
{
  "type": "chat",
  "message": "What research do we have on multi-agent systems?",
  "include_sources": true
}
```

## 🔧 Development

### Adding New Storage Backends

1. Implement the `KnowledgeRepository` interface in `shared_knowledge/backends/`
2. Add backend registration in `shared_knowledge/repository.py`
3. Update environment configuration

### Extending Agent Capabilities

Each agent is a standard Agentex project that can be extended independently:

- Add new MCP servers for external integrations
- Implement custom state machines for complex workflows
- Add new message types and handlers

## 📚 What You'll Learn

This project demonstrates:

- **Multi-agent orchestration** with shared persistent storage
- **Abstracted storage backends** for flexibility
- **RAG implementation** with vector search
- **MCP server integration** for external knowledge sources (Confluence and Web Search)
- **Agentex framework** best practices and patterns
