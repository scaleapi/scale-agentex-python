# WMT Conversationalist Agent

The **WMT Conversationalist** is an intelligent conversational agent that serves as the primary user interface for the Knowledge Hub system. It provides unified access to multiple information sources through natural language interaction.

## Overview

This agent acts as a knowledgeable assistant with access to:

🌐 **Web Search**: Current information and real-time data via MCP web search  
📚 **Confluence**: Organizational documentation and internal knowledge via Atlassian MCP Remote Server (requires user delegated OAuth2.1)  
🧠 **Deep Research Artifacts**: Previously generated comprehensive research reports from the knowledge database

## Capabilities

The conversationalist agent can:

- **Search the web** for current events and real-time information
- **Access Confluence spaces** for internal documentation and processes
- **Query deep research artifacts** that have been generated by the deep research agent
- **Combine information** from multiple sources to provide comprehensive answers
- **Maintain conversation context** across multiple turns
- **Cite sources** and provide attribution for information

## Architecture

The agent is built using:

- **Orchestration using OpenAI agent SDK** over tools
  - TODO: evaluate more complex orchestration (particularly as # of tools / complexity of tools becomes larger)
- **AgentEx Temporal workflows** for state management
- **Model Context Protocol (MCP)** for external tool access
- **Custom tools** for deep research artifact search
- **AWS Secrets Manager** integration for secure API key management

## Tools & Integrations

### MCP Servers

- **Web Search**: OpenAI's Hosted Web Search MCP Server for current information
- **Confluence**: Atlassian MCP Remote Server for organizational knowledge (requires user delegated OAuth2.1)

### Custom Tools

- **Deep Research Search**: OpenAI-compatible tool for searching previously generated research artifacts

## Running the Agent

### Prerequisites

1. **AgentEx backend** running locally
2. **Environment variables** configured (see Configuration section)
3. **MCP servers** available (web search and Confluence)

### Start the Agent

```bash
# From the wmt_conversationalist directory
export ENVIRONMENT=development
agentex agents run --manifest manifest.yaml
```

The agent will start on port 8000 and be available in the AgentEx web interface.

### Using the Web UI

```bash
# Start the AgentEx web interface (in separate terminal)
cd agentex-web
make dev

# Open http://localhost:3000 and select 'wmt-conversationalist'
```

## Configuration

### Environment Variables

Create a `.env` file in the project directory with:

```env
# Database Configuration (for future deep research integration)
DATABASE_URL=postgresql://username:password@localhost:5432/knowledge_hub

# Confluence Configuration (for MCP server)
CONFLUENCE_URL=https://yourorg.atlassian.net
CONFLUENCE_USERNAME=your-email@yourorg.com
CONFLUENCE_TOKEN=your-confluence-token
```

### AWS Secrets Manager

TODO: replace this with SGP auth once agentex sdk supports it

The agent retrieves the OpenAI API key from AWS Secrets Manager:

- **Secret name**: `team/EGPML/secret-store-key`
- **Region**: `us-west-2`
- **Profile**: `ml-admin`

## Project Structure

```
wmt_conversationalist/
├── project/
│   ├── __init__.py
│   ├── acp.py                    # ACP server setup
│   ├── workflow.py               # Main conversation workflow
│   ├── tools.py                  # Custom tools (deep research search)
│   ├── auth/
│   │   ├── __init__.py
│   │   └── openai.py            # OpenAI key management
│   └── run_worker.py            # Temporal worker
├── manifest.yaml                # Agent configuration
├── pyproject.toml              # Dependencies
├── Dockerfile                  # Container definition
├── dev.ipynb                   # Development notebook
└── env_example.txt             # Environment template
```

## Dependencies

Key dependencies managed via `uv`. Refer to pyproject.toml

## Development

### Adding Dependencies

```bash
# Add new packages
uv add package-name

# Sync dependencies
uv sync

# Run with uv
ENVIRONMENT=development uv run agentex agents run --manifest manifest.yaml
```

### Testing with Jupyter

Use the included `dev.ipynb` notebook for interactive testing:

```bash
# Start Jupyter or open in VS Code
uv run jupyter notebook dev.ipynb
```

### Debugging

- **Agent logs**: Check terminal output where agent is running
- **Temporal workflows**: Monitor at http://localhost:8080
- **Backend services**: Use `lzd` (LazyDocker) to monitor health
- **Web UI**: Inspect conversation history and responses

## Integration with Knowledge Hub

The conversationalist agent is part of the larger Knowledge Hub system:

1. **Conversationalist Agent** (port 8000): Provides user interface and search capabilities
2. **Deep Research Agent** (port 8001): Generates comprehensive research reports
3. **Shared Knowledge Repository**: PostgreSQL database with vector embeddings

The agent currently includes a placeholder for deep research artifact search that returns empty results. This will be connected to the actual knowledge database once the other agents are implemented.

## Troubleshooting

### Common Issues

1. **Agent not starting**

   - Verify `ENVIRONMENT=development` is set
   - Check if port 8000 is available
   - Ensure AgentEx backend is running

2. **OpenAI API key issues**

   - Run `aws sso login` to ensure credentials are refreshed
   - Run `sai dev` to ensure that the `ml-admin` profile is created under `~/.aws/config`

3. **MCP server issues**
   TODO: figure out how to auth MCP in deployments

   - Verify MCP servers are accessible
   - Check Confluence credentials and permissions
   - Test web search MCP server availability
